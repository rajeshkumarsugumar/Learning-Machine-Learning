{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_3D Images.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajeshkumarsugumar/Learning-Machine-Learning/blob/master/CNN_3D_Images.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2ePm44qx-pc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-epy5fXGGoQp",
        "colab_type": "text"
      },
      "source": [
        "# Check the Image Size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nEBOnX4GnRP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import cv2\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import matplotlib.pyplot as plt\n",
        " \n",
        "# folder_path=\"/Users/rajeshkumarsugumar/Documents/GitHub/Learning-Machine-Learning/3D-Printing-CNN/catergories/type_1/\"\n",
        "# img_size=50\n",
        "# for img in os.listdir(folder_path):\n",
        "#     img= cv2.imread(os.path.join(folder_path,img))\n",
        "#     img_gray= cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "#     img_gray_resize= cv2.resize(img_gray,(img_size,img_size))\n",
        "#     plt.imshow(img_gray_resize, cmap=\"gray\")\n",
        "#     plt.show()\n",
        "#     break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpbtbwenxsEd",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hgcd9CBxeKb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Python program to create \n",
        "# Image Classifier using CNN \n",
        "  \n",
        "# Importing the required libraries \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import pickle\n",
        "import time\n",
        "import cv2\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_QEnxt9Cge3",
        "colab_type": "text"
      },
      "source": [
        "# Create Pickle File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bqx9bqTdmh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "import random\n",
        "import pickle\n",
        "\n",
        "\n",
        "file_list = []\n",
        "class_list = []\n",
        "\n",
        "DATADIR = \"/content/drive/My Drive/Colab Notebooks/catergories/\"\n",
        "\n",
        "# All the categories you want your neural network to detect\n",
        "CATEGORIES = [\"type_1\", \"type_2\"]\n",
        "\n",
        "# The size of the images that your neural network will use\n",
        "IMG_SIZE = 50\n",
        "\n",
        "# Checking or all images in the data folder\n",
        "for category in CATEGORIES :\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    for img in os.listdir(path):\n",
        "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "\n",
        "training_data = []\n",
        "\n",
        "def create_training_data():\n",
        "    for category in CATEGORIES :\n",
        "        path = os.path.join(DATADIR, category)\n",
        "        class_num = CATEGORIES.index(category)\n",
        "        for img in os.listdir(path):\n",
        "            try :\n",
        "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "                training_data.append([new_array, class_num])\n",
        "            except Exception as e:\n",
        "                pass\n",
        "\n",
        "create_training_data()\n",
        "\n",
        "random.shuffle(training_data)\n",
        "\n",
        "X = [] #features\n",
        "y = [] #labels\n",
        "\n",
        "for features, label in training_data:\n",
        "    X.append(features)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "\n",
        "# Creating the files containing all the information about your model\n",
        "pickle_out = open(\"X.pickle\", \"wb\")\n",
        "pickle.dump(X, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_out = open(\"y.pickle\", \"wb\")\n",
        "pickle.dump(y, pickle_out)\n",
        "pickle_out.close()\n",
        "\n",
        "pickle_in = open(\"X.pickle\", \"rb\")\n",
        "X = pickle.load(pickle_in)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I_OBDBDCrFw",
        "colab_type": "text"
      },
      "source": [
        "# Model Training \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DioP_DQjyAVF",
        "colab_type": "code",
        "outputId": "54d34ac0-e817-45b3-b41e-0a74c878a7ea",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "NAME = \"3-conv-128-layer-dense-1-out-2-softmax-categorical-cross-2-CNN\"\n",
        " \n",
        "pickle_in = open(\"/content/drive/My Drive/Colab Notebooks/Pickle/X.pickle\",\"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        " \n",
        "pickle_in = open(\"/content/drive/My Drive/Colab Notebooks/Pickle/y.pickle\",\"rb\")\n",
        "y = pickle.load(pickle_in)\n",
        "y = to_categorical(y)\n",
        " \n",
        "X = X/255.0\n",
        " \n",
        "model = Sequential()\n",
        " \n",
        "model.add(Conv2D(128, (3, 3), input_shape=(50,50,1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Conv2D(128, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.3))\n",
        " \n",
        "model.add(Flatten())  \n",
        " \n",
        "model.add(Dense(128))\n",
        "model.add(Activation('relu'))\n",
        " \n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        " \n",
        "tensorboard = TensorBoard(log_dir=\"/content/drive/My Drive/Colab Notebooks/Logs2/{}\".format(NAME))\n",
        " \n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'],\n",
        "              )\n",
        " \n",
        "model.fit(X, y,\n",
        "          batch_size=32,\n",
        "          epochs=10,\n",
        "          validation_split=0.3,\n",
        "          callbacks=[tensorboard])\n",
        " \n",
        "model.save(f\"/content/drive/My Drive/Colab Notebooks/model/{NAME}.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 11200 samples, validate on 4800 samples\n",
            "Epoch 1/10\n",
            "11200/11200 [==============================] - 178s 16ms/sample - loss: 0.5046 - acc: 0.7223 - val_loss: 0.3132 - val_acc: 0.8579\n",
            "Epoch 2/10\n",
            "11200/11200 [==============================] - 177s 16ms/sample - loss: 0.3026 - acc: 0.8702 - val_loss: 0.2618 - val_acc: 0.8867\n",
            "Epoch 3/10\n",
            "11200/11200 [==============================] - 178s 16ms/sample - loss: 0.2411 - acc: 0.9051 - val_loss: 0.1647 - val_acc: 0.9360\n",
            "Epoch 4/10\n",
            "11200/11200 [==============================] - 178s 16ms/sample - loss: 0.1859 - acc: 0.9304 - val_loss: 0.2297 - val_acc: 0.9038\n",
            "Epoch 5/10\n",
            "11200/11200 [==============================] - 177s 16ms/sample - loss: 0.1499 - acc: 0.9443 - val_loss: 0.1979 - val_acc: 0.9312\n",
            "Epoch 6/10\n",
            "11200/11200 [==============================] - 178s 16ms/sample - loss: 0.1192 - acc: 0.9569 - val_loss: 0.1095 - val_acc: 0.9617\n",
            "Epoch 7/10\n",
            "11200/11200 [==============================] - 177s 16ms/sample - loss: 0.1094 - acc: 0.9604 - val_loss: 0.1599 - val_acc: 0.9433\n",
            "Epoch 8/10\n",
            "11200/11200 [==============================] - 177s 16ms/sample - loss: 0.0978 - acc: 0.9635 - val_loss: 0.0660 - val_acc: 0.9767\n",
            "Epoch 9/10\n",
            "11200/11200 [==============================] - 177s 16ms/sample - loss: 0.0933 - acc: 0.9666 - val_loss: 0.1072 - val_acc: 0.9644\n",
            "Epoch 10/10\n",
            "11200/11200 [==============================] - 177s 16ms/sample - loss: 0.0896 - acc: 0.9681 - val_loss: 0.1022 - val_acc: 0.9633\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EomxI6Y5CwKc",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1PsLvoG0YpF",
        "colab_type": "code",
        "outputId": "8f34e52c-6cec-4efa-d1f2-d6bb5a3ce6ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# def prepare(filepath):\n",
        "#     img_size = 80  \n",
        "#     img = cv2.imread(filepath, cv2.IMREAD_GRAYSCALE)/255  \n",
        "#     img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
        "#     img_resize = cv2.resize(img_array, (img_size, img_size))  \n",
        "#     return new_array.reshape(-1, img_size, img_size, 1)\n",
        "\n",
        "def prepare(file):\n",
        "    IMG_SIZE = 50\n",
        "    img_array = cv2.imread(file, cv2.IMREAD_GRAYSCALE)\n",
        "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
        "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
        "   \n",
        "prediction=model.predict(prepare(\"/content/drive/My Drive/Colab Notebooks/test_images/Finish_Type1_3_image_1v1p4.png\"))\n",
        "print(prediction)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGhk6iL1J6LW",
        "colab_type": "text"
      },
      "source": [
        "# Hyperparameter Tuning\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGYyKOn8FFYc",
        "colab_type": "code",
        "outputId": "e93d3b9e-6753-4288-c458-3758fd64068c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "import pickle\n",
        "import time\n",
        "from tensorflow.keras.utils import to_categorical\n",
        " \n",
        " \n",
        " \n",
        "pickle_in = open(\"/content/drive/My Drive/Colab Notebooks/Pickle/X.pickle\",\"rb\")\n",
        "X = pickle.load(pickle_in)\n",
        " \n",
        "pickle_in = open(\"/content/drive/My Drive/Colab Notebooks/Pickle/y.pickle\",\"rb\")\n",
        "y = pickle.load(pickle_in)\n",
        "y = to_categorical(y)\n",
        " \n",
        "X = X/255.0\n",
        " \n",
        "dense_layers = [0, 1, 2]\n",
        "layer_sizes = [32, 64, 128]\n",
        "conv_layers = [1, 2, 3]\n",
        " \n",
        "for dense_layer in dense_layers:\n",
        "    for layer_size in layer_sizes:\n",
        "        for conv_layer in conv_layers:\n",
        "            #NAME = f\"{conv_layer}-conv-{layer_size}-nodes-{dense_layer}-dense-{int(time.time()}\"\n",
        "            NAME = 'model-{}-conv-{}-Layers-{}-dense-{}'.format(conv_layer,layer_size,dense_layer,int(time.time()))\n",
        "            print(NAME)\n",
        " \n",
        "            model = Sequential()\n",
        " \n",
        "            model.add(Conv2D(layer_size, (3, 3), input_shape=X.shape[1:]))\n",
        "            model.add(Activation('relu'))\n",
        "            model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "            model.add(Dropout(0.3))\n",
        " \n",
        "            for l in range(conv_layer-1):\n",
        "                model.add(Conv2D(layer_size, (3, 3)))\n",
        "                model.add(Activation('relu'))\n",
        "                model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "                model.add(Dropout(0.3))\n",
        " \n",
        "            model.add(Flatten())\n",
        " \n",
        "            for _ in range(dense_layer):\n",
        "                model.add(Dense(layer_size))\n",
        "                model.add(Activation('relu'))\n",
        "                 \n",
        " \n",
        "            model.add(Dense(2))\n",
        "            model.add(Activation('softmax'))\n",
        " \n",
        "            tensorboard = TensorBoard(log_dir=f\"/content/drive/My Drive/Colab Notebooks/Logs2/{NAME}\")\n",
        " \n",
        "            model.compile(loss='categorical_crossentropy',\n",
        "                          optimizer='adam',\n",
        "                          metrics=['accuracy'],\n",
        "                          )\n",
        " \n",
        "            model.fit(X, y,\n",
        "                      batch_size=32,\n",
        "                      epochs=10,\n",
        "                      validation_split=0.3,\n",
        "                      callbacks=[tensorboard])\n",
        "             \n",
        "            model.save(f\"/content/drive/My Drive/Colab Notebooks/model/{NAME}.model\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "model-1-conv-32-Layers-0-dense-1571023830\n",
            "Train on 11200 samples, validate on 4800 samples\n",
            "Epoch 1/10\n",
            "11200/11200 [==============================] - 20s 2ms/sample - loss: 0.4649 - acc: 0.7682 - val_loss: 0.4055 - val_acc: 0.8056\n",
            "Epoch 2/10\n",
            "11200/11200 [==============================] - 19s 2ms/sample - loss: 0.3537 - acc: 0.8524 - val_loss: 0.3237 - val_acc: 0.8975\n",
            "Epoch 3/10\n",
            "11200/11200 [==============================] - 19s 2ms/sample - loss: 0.3364 - acc: 0.8622 - val_loss: 0.3020 - val_acc: 0.8683\n",
            "Epoch 4/10\n",
            "11200/11200 [==============================] - 19s 2ms/sample - loss: 0.3053 - acc: 0.8815 - val_loss: 0.2913 - val_acc: 0.9077\n",
            "Epoch 5/10\n",
            "11200/11200 [==============================] - 19s 2ms/sample - loss: 0.2924 - acc: 0.8858 - val_loss: 0.3229 - val_acc: 0.8752\n",
            "Epoch 6/10\n",
            "11200/11200 [==============================] - 19s 2ms/sample - loss: 0.2824 - acc: 0.8880 - val_loss: 0.2644 - val_acc: 0.9106\n",
            "Epoch 7/10\n",
            "11200/11200 [==============================] - 19s 2ms/sample - loss: 0.2699 - acc: 0.8949 - val_loss: 0.3397 - val_acc: 0.8313\n",
            "Epoch 8/10\n",
            "11200/11200 [==============================] - 19s 2ms/sample - loss: 0.2627 - acc: 0.8969 - val_loss: 0.2327 - val_acc: 0.9119\n",
            "Epoch 9/10\n",
            "11200/11200 [==============================] - 20s 2ms/sample - loss: 0.2579 - acc: 0.9018 - val_loss: 0.2251 - val_acc: 0.9173\n",
            "Epoch 10/10\n",
            "11200/11200 [==============================] - 19s 2ms/sample - loss: 0.2530 - acc: 0.9013 - val_loss: 0.2236 - val_acc: 0.9162\n",
            "model-2-conv-32-Layers-0-dense-1571024024\n",
            "Train on 11200 samples, validate on 4800 samples\n",
            "Epoch 1/10\n",
            "11200/11200 [==============================] - 36s 3ms/sample - loss: 0.4355 - acc: 0.7890 - val_loss: 0.2870 - val_acc: 0.8821\n",
            "Epoch 2/10\n",
            "11200/11200 [==============================] - 35s 3ms/sample - loss: 0.3047 - acc: 0.8714 - val_loss: 0.2433 - val_acc: 0.9054\n",
            "Epoch 3/10\n",
            "11200/11200 [==============================] - 34s 3ms/sample - loss: 0.2599 - acc: 0.8944 - val_loss: 0.2300 - val_acc: 0.9027\n",
            "Epoch 4/10\n",
            "11200/11200 [==============================] - 34s 3ms/sample - loss: 0.2432 - acc: 0.9052 - val_loss: 0.2477 - val_acc: 0.8863\n",
            "Epoch 5/10\n",
            "11200/11200 [==============================] - 34s 3ms/sample - loss: 0.2459 - acc: 0.9020 - val_loss: 0.2091 - val_acc: 0.9142\n",
            "Epoch 6/10\n",
            "11200/11200 [==============================] - 34s 3ms/sample - loss: 0.2409 - acc: 0.9024 - val_loss: 0.2373 - val_acc: 0.9073\n",
            "Epoch 7/10\n",
            "11200/11200 [==============================] - 33s 3ms/sample - loss: 0.2163 - acc: 0.9141 - val_loss: 0.2040 - val_acc: 0.9144\n",
            "Epoch 8/10\n",
            "11200/11200 [==============================] - 35s 3ms/sample - loss: 0.2166 - acc: 0.9142 - val_loss: 0.1815 - val_acc: 0.9331\n",
            "Epoch 9/10\n",
            "11200/11200 [==============================] - 35s 3ms/sample - loss: 0.2143 - acc: 0.9155 - val_loss: 0.2000 - val_acc: 0.9150\n",
            "Epoch 10/10\n",
            "11200/11200 [==============================] - 35s 3ms/sample - loss: 0.2136 - acc: 0.9151 - val_loss: 0.1847 - val_acc: 0.9248\n",
            "model-3-conv-32-Layers-0-dense-1571024371\n",
            "Train on 11200 samples, validate on 4800 samples\n",
            "Epoch 1/10\n",
            "11200/11200 [==============================] - 39s 3ms/sample - loss: 0.5373 - acc: 0.6923 - val_loss: 0.3804 - val_acc: 0.8475\n",
            "Epoch 2/10\n",
            "11200/11200 [==============================] - 38s 3ms/sample - loss: 0.3552 - acc: 0.8379 - val_loss: 0.2886 - val_acc: 0.8963\n",
            "Epoch 3/10\n",
            "11200/11200 [==============================] - 38s 3ms/sample - loss: 0.2919 - acc: 0.8738 - val_loss: 0.2342 - val_acc: 0.9033\n",
            "Epoch 4/10\n",
            "11200/11200 [==============================] - 38s 3ms/sample - loss: 0.2895 - acc: 0.8763 - val_loss: 0.2191 - val_acc: 0.9148\n",
            "Epoch 5/10\n",
            "11200/11200 [==============================] - 37s 3ms/sample - loss: 0.2621 - acc: 0.8907 - val_loss: 0.2597 - val_acc: 0.8871\n",
            "Epoch 6/10\n",
            "11200/11200 [==============================] - 38s 3ms/sample - loss: 0.2256 - acc: 0.9079 - val_loss: 0.1780 - val_acc: 0.9340\n",
            "Epoch 7/10\n",
            "11200/11200 [==============================] - 38s 3ms/sample - loss: 0.1969 - acc: 0.9213 - val_loss: 0.1926 - val_acc: 0.9217\n",
            "Epoch 8/10\n",
            "11200/11200 [==============================] - 38s 3ms/sample - loss: 0.1799 - acc: 0.9329 - val_loss: 0.2423 - val_acc: 0.9025\n",
            "Epoch 9/10\n",
            "11200/11200 [==============================] - 38s 3ms/sample - loss: 0.1674 - acc: 0.9354 - val_loss: 0.1785 - val_acc: 0.9277\n",
            "Epoch 10/10\n",
            "11200/11200 [==============================] - 38s 3ms/sample - loss: 0.1628 - acc: 0.9370 - val_loss: 0.2134 - val_acc: 0.9142\n",
            "model-1-conv-64-Layers-0-dense-1571024753\n",
            "Train on 11200 samples, validate on 4800 samples\n",
            "Epoch 1/10\n",
            "11200/11200 [==============================] - 31s 3ms/sample - loss: 0.4483 - acc: 0.7826 - val_loss: 0.3526 - val_acc: 0.8360\n",
            "Epoch 2/10\n",
            "11168/11200 [============================>.] - ETA: 0s - loss: 0.3597 - acc: 0.8497"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiCeF86LJ-jf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}